#!/usr/bin/env python3
import argparse
import os
import pickle
import sys
from multiprocessing import cpu_count

import numpy as np
from astropy import units
from astropy.table import Column, Table, hstack, vstack
from scipy.spatial import cKDTree

from table_tools import load_table


if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description='Assign properties from real data to a simulated '
                    'data catalogue based on the nearest neighbours in the '
                    'space of a set of data attributes (e.g. object '
                    'magnitudes).')

    sim_group = parser.add_argument_group('simulation')
    sim_group.add_argument(
        '-s', '--simulated', required=True,
        help='file path of the simulation table')
    sim_group.add_argument(
        '--s-format', default='fits',
        help='astropy.table format specifier of the simulation table')
    sim_group.add_argument(
        '--s-attr', nargs='*', required=True,
        help='list of column names of simulation attributes based on which '
             'the nearest neighbour data objects are looked up')
    sim_group.add_argument(
        '--s-prop', nargs='*',
        help='column names at which the assigend properties will be stored in '
             'the simulation table (default: copy --dprop)')

    data_group = parser.add_argument_group('data')
    data_group.add_argument(
        '-d', '--data', required=True,
        help='file path of the data table')
    data_group.add_argument(
        '--d-format', default='fits',
        help='astropy.table format specifier of the data table')
    data_group.add_argument(
        '--d-attr', nargs='*', required=True,
        help='list of column names of data attributes based on which the '
             'nearest neighbour search is done')
    data_group.add_argument(
        '--d-prop', nargs='*', required=True,
        help='column name of property in data table')
    data_group.add_argument(
        '--d-sparse', type=int, default=1,
        help='use only every --d-sparse entry in the input data table')

    params_group = parser.add_argument_group('parameters')
    params_group.add_argument(
        '-t', '--tree', default="",
        help='python pickle file path at which the generated search tree is '
             'stored or loaded from if existing '
             '(python%s.%s)' % (sys.version[0], sys.version[1]))
    params_group.add_argument(
        '--r-max', type=float,
        help='maximum Minkowski distance at which neighbours are considered a '
             'match, this requires specifying --fallback')
    params_group.add_argument(
        '--fallback', nargs='*',
        help='value to assign if no neighbour is found within --r-max, one '
             'for each drawn property (bools can be represented by "True" or '
             '"False")')
    params_group.add_argument(
        '-o', '--output', required=True, help='file path of output table')
    params_group.add_argument(
        '--o-format', default='fits',
        help='astropy.table format specifier of the output table '
             '(default: %(default)s)')
    params_group.add_argument(
        '--threads', type=int, default=cpu_count(),
        help='number of threads to use for the nearest neighbour query')

    args = parser.parse_args()

    setattr(args, "threads", min(cpu_count(), max(1, args.threads)))

    if args.s_prop is None:  # copy column names from input data
        setattr(args, "s_prop", args.d_prop)

    if args.r_max is not None and args.fallback is None:
        raise parser.error("--fallback is required with --r-max")

    # load and check the input data columns of the simulation table
    simul = load_table(args.simulated, args.s_format, args.s_attr)
    # load and check the data table, apply optinal sparse sampling
    data = load_table(
        args.data, args.d_format,
        [*args.d_attr, *args.d_prop])[::args.d_sparse]
    # get the data columns to match simulation against data
    simul_attr = np.transpose([simul[s] for s in args.s_attr])
    data_attr = np.transpose([data[s] for s in args.d_attr])
    data_props = data[tuple(args.d_prop)]
    # this is an astropy.table.Table with shape (n_data, n_props)
    n_props = len(data_props.columns)
    n_data = len(data_props)

    # get the property data type
    if args.fallback is not None:
        fallbacks = [f for f in args.fallback]
        # convert the input fallback values to data of valid type
        if len(fallbacks) != n_props:
            raise ValueError(
                "number of properties is %d, but number of fallbacks is %d" % (
                    n_props, len(fallbacks)))
        for i in range(n_props):
            dtype = data_props.dtype[i]
            colname = data_props.colnames[i]
            # store the converted fallback values as astropy.table.Column
            # for compatibility with the data table
            try:
                if dtype.kind == "b":  # conversion of booleans
                    # TODO: this fails silently if the fallback is misspelled
                    fallbacks[i] = Column(
                        [args.fallback[i].upper() == "TRUE"],
                        colname, dtype=dtype)
                else:
                    fallbacks[i] = Column(
                        [args.fallback[i]], colname, dtype=dtype)
            except ValueError:
                raise ValueError(
                    "failed to convert fallback '%s' to type '%s'" % (
                        args.fallback[i], dtype.str))
        # Append the fallbacks into the property vectors. If neighbours are
        # outside r_max, cKDTree.query will point to index len(property) and
        # therefore at the newly append fallback value
        fallback_row = Table(fallbacks)
        data_props = vstack([data_props, fallback_row])

    # create or load the nearest neighbour search tree
    if os.path.exists(args.tree):
        print("load existing search tree from: %s" % args.tree)
        with open(args.tree, "rb") as f:
            tree = pickle.load(f)
        # verify the tree structure
        if not isinstance(tree, cKDTree):
            sys.exit("ERROR: pickled object ist not a 'cKDTree' instance")
        n, m, = data_attr.shape
        if tree.m != m or tree.n != n:
            message = "ERROR: data with dimensions (%d, %d) does not " % (n, m)
            message += "match loaded tree with (%d, %d)" % (tree.n, tree.m)
            sys.exit(message)
        # verify the data values to be sure that the data has not changed
        # NOTE: this is much faster than creating a new tree every time
        for i in range(m):
            if not np.isclose(
                    tree.data[:, i], data_attr[:, i], equal_nan=True).all():
                message = "ERROR: data in dimension %d " % i
                message += "of tree does not match data"
                sys.exit(message)
    else:
        print("build search tree for '%s'" % ", ".join(args.d_attr))
        tree = cKDTree(data_attr)
        # write the tree if the path string is not empty
        if args.tree != "":
            print("write search tree to python pickle file")
            if os.path.exists(os.path.dirname(args.tree)):
                with open(args.tree, "wb") as f:
                    pickle.dump(tree, f)
            else:
                sys.exit(
                    "ERROR: folder does not exit: %s" %
                    os.path.dirname(args.tree))

    print("assign values from nearest data neighbour")
    dist, idx_nearest = tree.query(
        simul_attr, k=1, distance_upper_bound=args.r_max, n_jobs=args.threads)

    # create a new output table
    table = Table()
    for i, (s_prop, d_prop) in enumerate(zip(args.s_prop, args.d_prop)):
        table[s_prop] = Column(
            # look up the property values of the nearest data neightbours and
            # store them
            data_props[d_prop][idx_nearest], dtype=data_props.dtype[i],
            description="drawn via %s from file: %s" % (
                ", ".join(args.d_attr), args.data))

    # write to specified output path
    print("write table to: %s" % args.output)
    table.write(args.output, format=args.o_format, overwrite=True)
