#!/usr/bin/env python3
import argparse
import multiprocessing
import os
import sys
from multiprocessing import cpu_count

import numpy as np
from astropy import units
from astropy.table import Column, Table
from data_table import load_table
from scipy.optimize import root_scalar
from scipy.special import gamma, gammainc


def f_R_e(R, R_e_Disk, R_e_Bulge, f_B, percentile=0.5):
    if R_e_Disk == 0.0 or f_B == 1.0:
        disk_term = 0.0
    else:
        x_D = 1.6721 * R / R_e_Disk
        disk_term = (1.0 - f_B) * gammainc(2, x_D)
    if R_e_Bulge == 0.0 or f_B == 0.0:
        bulge_term = 0.0
    else:
        x_B = 7.6697 * (R / R_e_Bulge) ** 0.25
        bulge_term = f_B * gammainc(8, x_B)
    return disk_term + bulge_term - percentile


def f_R_e_derivative(R, R_e_Disk, R_e_Bulge, f_B, *args):
    if R_e_Disk == 0.0 or f_B == 1.0:
        disk_term = 0.0
    else:
        b_1 = 1.6721
        x_D = b_1 * R / R_e_Disk
        disk_term = (1.0 - f_B) * np.exp(-x_D) * x_D / R_e_Disk * b_1
    if R_e_Bulge == 0.0 or f_B == 0.0:
        bulge_term = 0.0
    else:
        b_4 = 7.6697
        x_B = b_4 * (R / R_e_Bulge) ** 0.25
        bulge_term = (
            f_B * np.exp(-x_B) / 5040.0 * x_B**4 / R_e_Bulge * b_4**4 / 4.0)
    return disk_term + bulge_term


def find_percentile(
        percentile, R_e_Disk, R_e_Bulge, f_B, method="newton"):
    assert(0.0 <= f_B <= 1.0)
    assert(R_e_Disk >= 0.0 and R_e_Bulge >= 0.0)
    x0 = (1.0 - f_B) * R_e_Disk + f_B * R_e_Bulge
    solution = root_scalar(
        f_R_e, fprime=f_R_e_derivative, x0=x0, method=method, maxiter=100,
        args=(R_e_Disk, R_e_Bulge, f_B, percentile))
    return solution.root


def root_function(args):
    return find_percentile(*args)


if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description='Compute the signal-to-noise ratio correction factor '
                    'for an extended object compared to a point source '
                    'assuming a n=4 Sersic profile for the bulge and a n=1 '
                    'Sersic profile for the disk component. The size is '
                    'defined in terms of a fraction of the total emitted flux '
                    '(i.e. 0.5 for the half-light radius.')

    data_group = parser.add_argument_group('data')
    data_group.add_argument(
        '-i', '--input', required=True, help='file path of input data table')
    data_group.add_argument(
        '--iformat', default='fits',
        help='astropy.table format specifier of the input table '
             '(default: %(default)s)')
    data_group.add_argument(
        '-o', '--output', required=True, help='file path of output table')
    data_group.add_argument(
        '--oformat', default='fits',
        help='astropy.table format specifier of the output table '
             '(default: %(default)s)')

    params_group = parser.add_argument_group('parameters')
    params_group.add_argument(
        '--bulge-ratio', required=True,
        help='column name of bulge-to-total-flux ratio')
    params_group.add_argument(
        '--bulge-size', required=True,
        help='column name of projected bulge size (half light radius) in '
             'arcsec')
    params_group.add_argument(
        '--disk-size', required=True,
        help='column name of projected disk size (half light radius) in '
             'arcsec')
    params_group.add_argument(
        '--ba-ratio',
        help='column name of minor-to-major axis ratio')
    params_group.add_argument(
        '--flux-frac', type=float, default=0.5,
        help='fraction of total flux emitted from within computed radius '
             '(default: %(default)s)')
    params_group.add_argument(
        '--psf', nargs='*', type=float, required=True,
        help='list of point-spread functions in arcsec, '
             'additionally computes observed galaxy sizes (PSF convolved)')
    params_group.add_argument(
        '--filters', nargs='*',
        help='filter names associated with each --psf given (optional, used '
             'to name the output table columns)')
    params_group.add_argument(
        '--scale', type=float, default=1.0,
        help='factor to scale the aperture size (default: %(default)s)')
    params_group.add_argument(
        '--threads', type=int, default=cpu_count(),
        help='number of threads to use (default: %(default)s)')

    args = parser.parse_args()

    setattr(args, "threads", min(cpu_count(), max(0, args.threads)))

    data = load_table(
        args.input, args.iformat,
        [args.bulge_ratio, args.bulge_size, args.disk_size, args.ba_ratio])

    # generate list of PSF sizes and output columns names
    if args.filters is not None:
        if len(args.psf) != len(args.filters):
            sys.exit("ERROR: length of --filter and --psf lists do not match")
        for psf in args.psf:
            if psf <= 0.0:
                sys.exit("ERROR: PSF size must be positive")
    else:
        setattr(
            args, "filters", ["filter%d" % d for d in range(len(args.psf))])
    psf_sizes = {
        key: val for key, val in zip(args.filters, args.psf)}

    # compute intrinsic galaxy sizes
    bulge_ratio = data[args.bulge_ratio]
    bulge_size = data[args.bulge_size]
    disk_size = data[args.disk_size]
    ba_ratio = data[args.ba_ratio]
    flux_fraction = np.full_like(bulge_ratio, args.flux_frac)
    # create an argument list for map / multiprocessing.pool.map
    arguments = list(zip(flux_fraction, disk_size, bulge_size, bulge_ratio))
    print(
        "compute intrinsic galaxy sizes" +
        (" using %d threads" % args.threads if args.threads > 1 else ""))
    if args.threads > 1:
        with multiprocessing.Pool(args.threads) as pool:
            galaxy_size = pool.map(root_function, arguments)
    else:
        galaxy_size = tuple(map(root_function, arguments))
    # create the output data table
    galaxy_major = np.asarray(galaxy_size) * args.scale
    galaxy_minor = galaxy_major * ba_ratio
    galaxy_area = np.pi * galaxy_major * galaxy_minor

    # compute the convoluted galaxy properties and collect the data
    print("compute observed galaxy sizes")
    table = Table()
    table["R_E"] = Column(
        galaxy_size, unit=units.arcsec,
        description="effective radius, L(<R_E) = %f L_tot" % args.flux_frac)
    table["aper_a_intr"] = Column(
        galaxy_major, unit=units.arcsec,
        description="PSF corrected aperture major axis")
    table["aper_area_intr"] = Column(
        galaxy_area, unit=units.arcsec**2,
        description="PSF corrected aperture area")
    for filt in args.filters:
        psf = psf_sizes[filt]
        print("processing filter '%s' (PSF=%.2f\")" % (filt, psf))
        observed_major = np.sqrt(galaxy_major**2 + psf**2)
        observed_minor = np.sqrt(galaxy_minor**2 + psf**2)
        observed_ba = observed_minor / observed_major
        observed_area = np.pi * observed_major * observed_minor
        psf_area = np.pi * psf**2
        sn_weight = np.sqrt(psf_area / observed_area)
        # collect data in table
        table["aper_a_%s" % filt] = Column(
            observed_major, unit=units.arcsec,
            description="aperture major axis")
        table["aper_ba_ratio_%s" % filt] = Column(
            observed_ba,
            description="aperture minor-to-major axis-ratio")
        table["aper_area_%s" % filt] = Column(
            observed_area, unit=units.arcsec**2,
            description="aperture area")
        table["sn_factor_%s" % filt] = Column(
            sn_weight,
            description="signal-to-noise correction factor for extended "
                        "source")

    # write to specified output path
    print("write table to: %s" % args.output)
    table.write(args.output, format=args.oformat, overwrite=True)
