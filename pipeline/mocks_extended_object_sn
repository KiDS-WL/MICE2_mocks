#!/usr/bin/env python3
import argparse
import multiprocessing
import os
import sys
from multiprocessing import cpu_count

import numpy as np
from scipy.optimize import root_scalar
from scipy.special import gamma, gammainc  # Gamma and incomplete Gamma

from h5table.table import HDF5table
from MICE2_mocks import pipeline


def f_R_e(R, R_e_Disk, R_e_Bulge, f_B, percentile=0.5):
    """
    Function used to find the effective radius of a galaxy with combined
    bulge and disk component. Computes the fraction of the total flux emitted
    within a radius R minus a percentile. The percentile sets the zero-point
    of this function.

    By running a root-finding algorithm, the radius corresponding to a given
    percentile of emitted flux within can be computed. Setting the percentile
    to 0.5 yields the effective radius, the radius from within which 50% of the
    total flux are emitted.

    Parameters
    ----------
    R : float
        Radius (angular) at which to evaluate the function.
    R_e_Disk : float
        Effective angular size of the disk component.
    R_e_Bulge : float
        Effective angular size of the bulge component.
    f_B : float
        Bulge fraction, (flux bulge / total flux).
    percentile : float
        The percentile subtracted from the calculated flux fraction within R.

    Returns
    -------
    flux_fraction_offset : float
        Fraction of flux emitted within R minus percentile.
    """
    if R_e_Disk == 0.0 or f_B == 1.0:  # no disk component
        disk_term = 0.0
    else:  # evaluate the integrated Sersic n=1 profile
        x_D = 1.6721 * R / R_e_Disk
        disk_term = (1.0 - f_B) * gammainc(2, x_D)
    if R_e_Bulge == 0.0 or f_B == 0.0:  # no bulge component
        bulge_term = 0.0
    else:  # evaluate the integrated Sersic n=4 profile
        x_B = 7.6697 * (R / R_e_Bulge) ** 0.25
        bulge_term = f_B * gammainc(8, x_B)
    # disk_term and bulge_term are already normalized by the total flux
    flux_fraction_offset = disk_term + bulge_term - percentile
    return flux_fraction_offset


def f_R_e_derivative(R, R_e_Disk, R_e_Bulge, f_B, *args):
    """
    Derivative of f_R_e wrt. the radius used by the root-finding algorithm.

    Parameters
    ----------
    R : float
        Radius (angular) at which to evaluate the derivative.
    R_e_Disk : float
        Effective angular size of the disk component.
    R_e_Bulge : float
        Effective angular size of the bulge component.
    f_B : float
        Bulge fraction, (flux bulge / total flux).

    Returns
    -------
    flux_fraction_der : float
        Derivative of f_R_e.
    """
    if R_e_Disk == 0.0 or f_B == 1.0:  # no disk component
        disk_term = 0.0
    else:  # evaluate the derivative of the integrated Sersic n=1 profile
        b_1 = 1.6721
        x_D = b_1 * R / R_e_Disk
        disk_term = (1.0 - f_B) * np.exp(-x_D) * x_D / R_e_Disk * b_1
    if R_e_Bulge == 0.0 or f_B == 0.0:  # no bulge component
        bulge_term = 0.0
    else:  # evaluate the derivative of the integrated Sersic n=4 profile
        b_4 = 7.6697
        x_B = b_4 * (R / R_e_Bulge) ** 0.25
        bulge_term = (
            f_B * np.exp(-x_B) / 5040.0 * x_B**4 / R_e_Bulge * b_4**4 / 4.0)
    # combined derivative is sum of disk and bulge derivatives
    flux_fraction_der = disk_term + bulge_term
    return flux_fraction_der


def find_percentile(
        percentile, R_e_Disk, R_e_Bulge, f_B, method="newton"):
    """
    Compute the radius within which a certain percentile of flux is emitted
    using the scipy.optimize.root_scalar root-finding algorithm. By default
    the Newton's method is used.

    Parameters
    ----------
    percentile : float
        The percentile of emitted flux from within the radius of interest.
    R_e_Disk : float
        Effective angular size of the disk component.
    R_e_Bulge : float
        Effective angular size of the bulge component.
    f_B : float
        Bulge fraction, (flux bulge / total flux).
    method : sting
        Root-finding method to use (from scipy.optimize.root_scalar).

    Returns
    -------
    solution.root : float
        The radius within which the percentile of flux is emitted.
    """
    assert(0.0 <= f_B <= 1.0)
    assert(R_e_Disk >= 0.0 and R_e_Bulge >= 0.0)
    x0 = (1.0 - f_B) * R_e_Disk + f_B * R_e_Bulge
    solution = root_scalar(
        f_R_e, fprime=f_R_e_derivative, x0=x0, method=method, maxiter=100,
        args=(R_e_Disk, R_e_Bulge, f_B, percentile))
    return solution.root


def root_function(args):
    """
    Wrapper for multiprocessing
    """
    return find_percentile(*args)


if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description='Compute the signal-to-noise ratio correction factor '
                    'for an extended object compared to a point source '
                    'assuming a n=4 Sersic profile for the bulge and a n=1 '
                    'Sersic profile for the disk component. The size is '
                    'defined in terms of a fraction of the total emitted flux '
                    '(i.e. 0.5 for the half-light radius.')
    parser.add_argument(
        'dataset', help='HDF5 data set with MICE2 raw data')
    parser.add_argument(
        '-c', '--chunksize', type=int, default=100000,
        help='HDF5 data set with MICE2 raw data (default: %(default)s)')
    parser.add_argument(
        '--flux-frac', type=float, default=0.5,
        help='fraction of total flux emitted from within computed radius '
             '(default: %(default)s)')
    parser.add_argument(
        '--psf', nargs='*', type=float, required=True,
        help='list of point-spread functions in arcsec, '
             'additionally computes observed galaxy sizes (PSF convolved)')
    parser.add_argument(
        '--filters', nargs='*', required=True,
        help='filter names associated with each --psf given (optional, used '
             'to name the output table columns)')
    parser.add_argument(
        '--scale', type=float, default=1.0,
        help='factor to scale the aperture size (default: %(default)s)')
    parser.add_argument(
        '--threads', type=int, default=cpu_count(),
        help='number of threads to use (default: %(default)s)')
    args = parser.parse_args()
    args.threads = min(cpu_count(), max(1, args.threads))

    logger = pipeline.pipe_logger(__file__)

    index_path = "unique_gal_id"
    with HDF5table(args.dataset, index_path, "w", True) as table:

        # find the shape columns
        path_dict = {
            "bulge ratio": "bulge_fraction",
            "bulge size": "bulge_length",
            "disk size": "disk_length",
            "axis ratio": "bulge_axis_ratio"}
        for name, path in path_dict.items():
            if path not in table:
                message = "{:} column {:} not found in data set"
                logger.error(message.format(name, path))
                raise KeyError(message.format(name, path))

        # generate list of PSF sizes and output columns names
        if len(args.psf) != len(args.filters):
            message = "length of --filter and --psf lists do not match"
            logger.error(message)
            raise ValueError(message)
        for psf in args.psf:
            if psf <= 0.0:
                message = "PSF size must be positive"
                logger.error(message)
                raise ValueError(message)
        psf_sizes = {
            key: val for key, val in zip(args.filters, args.psf)}

        logger.info("computing intrinsic galaxy sizes")
        for path in ["R_E", "aper_a_intr", "aper_area_intr"]:
            try:
                table.add_column(path, dtype=np.float32)
            except ValueError:
                message = "column '{:}' will be overwritten"
                logger.warning(message.format(path))
        # iterate the data set in chunks and compute the apertures
        for start, end in table.iter_rows(args.chunksize):
            # compute intrinsic galaxy sizes
            bulge_ratio = table.read_column(
                path_dict["bulge ratio"], start=start, end=end)
            bulge_size = table.read_column(
                path_dict["bulge size"], start=start, end=end)
            disk_size = table.read_column(
                path_dict["disk size"], start=start, end=end)
            ba_ratio = table.read_column(
                path_dict["axis ratio"], start=start, end=end)
            flux_fraction = np.full_like(bulge_ratio, args.flux_frac)
            # compute the radius of galaxies that emits a certain fraction of
            # the total luminosity
            with multiprocessing.Pool(args.threads) as pool:
                arguments = list(zip(
                    flux_fraction, disk_size, bulge_size, bulge_ratio))
                chunksize = args.chunksize // args.threads + 1
                galaxy_size = pool.map(
                    root_function, arguments, chunksize=chunksize)
            # compute the intrinsic galaxy major and minor axes and area
            galaxy_major = np.asarray(galaxy_size) * args.scale
            galaxy_minor = galaxy_major * ba_ratio
            galaxy_area = np.pi * galaxy_major * galaxy_minor
            # write the data
            table.write_column(
                galaxy_size, "R_E", start=start, end=end)
            # description: "effective radius, L(<R_E) = %f L_tot" % args.flux_frac
            table.write_column(
                galaxy_major, "aper_a_intr", start=start, end=end)
            # description: "PSF corrected aperture major axis"
            table.write_column(
                galaxy_area, "aper_area_intr", start=start, end=end)
            # description: "PSF corrected aperture area"
        logger.info("done writing")

        # compute the observational galaxy sizes utilizing the PSF per filter
        for filt in args.filters:
            logger.info(
                "computing observed galaxy sizes in filter '{:}'".format(filt))
            psf = psf_sizes[filt]
            for path in [
                    "aper_a_{:}", "aper_ba_ratio_{:}",
                    "aper_area_{:}", "sn_factor_{:}"]:
                try:
                    table.add_column(path.format(filt), dtype=np.float32)
                except ValueError:
                    message = "column '{:}' will be overwritten"
                    logger.warning(message.format(path.format(filt)))
            # iterate the data set in chunks and compute the apertures
            for start, end in table.iter_rows(args.chunksize):
                ba_ratio = table.read_column(
                    path_dict["axis ratio"], start=start, end=end)
                galaxy_major = table.read_column(
                    "aper_a_intr", start=start, end=end)
                # "convolution" with the PSF
                observed_major = np.sqrt(galaxy_major**2 + psf**2)
                observed_minor = np.sqrt((galaxy_major * ba_ratio)**2 + psf**2)
                # compute the observed axis ratio
                observed_ba = observed_minor / observed_major
                # compute the aperture area
                observed_area = np.pi * observed_major * observed_minor
                psf_area = np.pi * psf**2
                # compute the S/N correction by comparing the aperture area to the PSF
                sn_weight = np.sqrt(psf_area / observed_area)
                # write the data
                table.write_column(
                    observed_major, "aper_a_{:}".format(filt),
                    start=start, end=end)
                # description: "aperture major axis"
                table.write_column(
                    observed_ba, "aper_ba_ratio_{:}".format(filt),
                    start=start, end=end)
                # description: "aperture minor-to-major axis-ratio"
                table.write_column(
                    observed_area, "aper_area_{:}".format(filt),
                    start=start, end=end)
                # description: "aperture area"
                table.write_column(
                    sn_weight, "sn_factor_{:}".format(filt),
                    start=start, end=end)
                # description: "signal-to-noise correction factor for extended source")
            logger.info("done writing")
