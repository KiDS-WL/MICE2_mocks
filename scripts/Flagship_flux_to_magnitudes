#!/usr/bin/env python3
import argparse
import os
import sys

from mock_processing import PipeLogger, expand_path, open_datastore
from mock_processing.Flagship import flux_to_magnitudes_wrapped
from mock_processing.parallel import ParallelTable
from mock_processing.photometry import load_photometry
from mock_processing.utils import ModificationStamp, create_column


parser = argparse.ArgumentParser(
    description="Convert fluxes in Flagship to AB magnitudes.")
parser.add_argument(
    "datastore", type=expand_path,
    help="directory in which the data store is located")
parser.add_argument(
    "--flux",
    help="sub-directory within data store which contains the input fluxes")
parser.add_argument(
    "--mag",
    help="sub-directory within data store where the AB magnitudes are stored")
parser.add_argument(
    "--threads", type=int, default=4,
    help="number of threads to use (default: %(default)s)")


def main():

    args = parser.parse_args()
    logger = PipeLogger(__file__, args.datastore)
    timestamp = ModificationStamp(sys.argv)

    # apply the evolution correction to the model magnitudes
    with open_datastore(args.datastore, logger, readonly=False) as table:

        pool = ParallelTable(table, logger)
        pool.set_worker(flux_to_magnitudes_wrapped)

        # find all flux columns
        try:
            model_fluxes = load_photometry(table, args.flux)
        except KeyError as e:
            logger.handleException(e)

        # create the output columns
        for key, flux_path in model_fluxes.items():
            # create new output columns
            mag_path = os.path.join(args.mag, key)
            column = create_column(
                table, logger, mag_path, dtype=table[flux_path].dtype.str,
                attr={
                    "description":
                    "{:} converted to AB magnitudes".format(flux_path)},
                overwrite=True)
            timestamp.register(column)
            # add columns to call signature
            pool.add_argument_column(flux_path)
            pool.add_result_column(mag_path)

        # compute and store the corrected magnitudes in parallel
        pool.execute(args.threads)

        logger.info("updating headers and closing data store")
        timestamp.finalize()
    # close the table and flush data
    logger.info("computation completed for {:,d} entries".format(len(table)))


if __name__ == "__main__":
    main()
