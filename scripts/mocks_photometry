#!/usr/bin/env python
import argparse
import os
import sys

from mock_processing import PipeLogger, expand_path, open_datastore
from mock_processing.config import DumpPhotometryConfig, load_photometry_config
from mock_processing.parallel import ParallelTable
from mock_processing.photometry import (load_photometry,
                                        photometry_realisation_wrapped)
from mock_processing.utils import (ModificationStamp, create_column,
                                   require_column)


parser = argparse.ArgumentParser(
    description="Create a photometry realisation based on simulated apertures "
                "and magnitude limits.",
    add_help=False)
parser.register("action", "dump", DumpPhotometryConfig)

parser.add_argument(
    "datastore", type=expand_path,
    help="directory in which the data store is located")

parser.add_argument(
    "--mag",
    help="sub-directory within data store which contains the input magnitudes")
parser.add_argument(
    "--real",
    help="sub-directory within data store where the photometry realisations "
         "are stored")
parser.add_argument(
    "--method", choices=("SExtractor", "GAaP"), default="SExtractor",
    help="photometry algorthim to apply (default: %(default)s)")
parser.add_argument(
    "-c", "--config", type=expand_path, required=True,
    help="parameter file in TOML format that defines the properties of the "
         "photometry realisation and the method parameters (use --dump to "
         "obtain a default parameter file)")
parser.add_argument(
    "--no-aper", action="store_true",
    help="do not apply the aperture size depending signal-to-noise "
         "correction, running 'mocks_apertures' is no longer required")
parser.add_argument(
    "--seed", default="sapling",
    help="string to seed the random generator (default: %(default)s, results "
         "are only reproducible for the same number of threads)")
parser.add_argument(
    "--threads", type=int, default=16,
    help="number of threads to use (default: %(default)s)")

help_group = parser.add_argument_group("help and documentation")
help_group.add_argument(
    "-h", "--help", action="help",
    help="show this help message and exit")
help_group.add_argument(
    "--dump", nargs=0, action="dump",
    help="dump a default photometry configuration file to stdout and exit")


def main():

    args = parser.parse_args()
    logger = PipeLogger(__file__, args.datastore)
    timestamp = ModificationStamp(sys.argv)

    # check the configuration file
    config = load_photometry_config(args.config, logger)

    # apply the magnification correction to the model magnitudes
    with open_datastore(args.datastore, logger, readonly=False) as table:

        # find all magnitude columns
        try:
            input_mags, _ = load_photometry(table, args.mag)
        except KeyError as e:
            logger.handleException(e)

        pool = ParallelTable(table, logger)

        # select the required magnitude columns
        available = set(input_mags.keys())
        missing = set(config.filter_names) - available
        if len(missing) > 0:
            message = "requested filters not found: {:}".format(
                ", ".join(missing))
            logger.handleException(KeyError(message))
        
        # initialize the photometry generation
        pool.set_worker(photometry_realisation_wrapped)
        pool.add_argument_constant(config)

        # collect the filter-specific arguments
        for key in config.filter_names:
            # 1) magnitude column
            mag_path = input_mags[key]
            require_column(table, logger, mag_path, "{:}-band".format(key))
            pool.add_argument_column(mag_path)
            # 2) magnitude limit
            pool.add_argument_constant(config.limits[key])
            # 3) S/N correction factors
            if args.no_aper:
                pool.add_argument_constant(1.0)  # aperture correction disabled
            else:
                snr_path = "apertures/{:}/snr_correction/{:}".format(
                    args.method, key)
                require_column(
                    table, logger, mag_path,
                    "{:}-band S/N correction".format(key))
                pool.add_argument_column(snr_path)

        output_columns = (  # for each filter three output columns are required
            ("{:}/{:}",
             "{:} photometry realisation (from {:}, limit: {:.2f} mag)"),
            ("{:}/{:}_err",
             "{:} photometric error (from {:}, limit: {:.2f} mag)"))
        # make the output columns for each filter
        for key in config.filter_names:
            for out_path, desc in output_columns:
                column = create_column(
                    table, logger, out_path.format(args.real, key),
                    dtype=table[mag_path].dtype.str,
                    overwrite=True, attr={
                        "description": desc.format(
                            args.method, mag_path, config.limits[key])})
                timestamp.register(column)
                pool.add_result_column(out_path.format(args.real, key))

        # compute and store the corrected magnitudes
        pool.execute(args.threads, seed=args.seed)

        logger.info("updating headers and closing data store")
        timestamp.finalize()
    # close the table and flush data
    logger.info("computation completed for {:,d} entries".format(len(table)))


if __name__ == "__main__":
    main()
