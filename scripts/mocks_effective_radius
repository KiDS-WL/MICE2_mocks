#!/usr/bin/env python
import argparse
import os
import sys

from mock_processing import PipeLogger, expand_path, open_datastore
from mock_processing.parallel import ParallelTable
from mock_processing.photometry import find_percentile_wrapped
from mock_processing.utils import (ModificationStamp, create_column,
                                   require_column)


parser = argparse.ArgumentParser(
    description="Compute the projected effective galaxy radius from galaxy "
                "bulge (Sersic n=4) and disk (Sersic n=1) components.")
parser.add_argument(
    "datastore", type=expand_path,
    help="directory in which the data store is located")
parser.add_argument(
    "--flux-frac", type=float, default=0.5,
    help="fraction of the total flux emitted from within computed radius "
         "(default: %(default)s)")
parser.add_argument(
    "--threads", type=int,
    help="number of threads to use (default: all)")


def main():

    args = parser.parse_args()
    logger = PipeLogger(__file__, args.datastore)
    timestamp = ModificationStamp(sys.argv)

    # apply the magnification correction to the model magnitudes
    with open_datastore(args.datastore, logger, readonly=False) as table:

        pool = ParallelTable(table, logger)
        pool.set_worker(find_percentile_wrapped)

        pool.add_argument_constant(args.flux_frac)

        # find disk and bulge component columns
        input_columns = (
            ("disk size", "shape/disk/size"),
            ("bulge size", "shape/bulge/size"),
            ("bulge fraction", "shape/bulge/fraction"))
        for col_desc, path in input_columns:
            require_column(table, logger, path, col_desc)
            pool.add_argument_column(path)

        r_e_path = "shape/R_effective"
        # create the output column
        column = create_column(
            table, logger, r_e_path, dtype="f4",
            attr={
                "description":
                "effective radius (emitting {:.1%} of the flux)".format(
                    args.flux_frac)},
            overwrite=True)
        timestamp.register(column)
        # add column to call signature
        pool.add_result_column(r_e_path)

        # compute and store the corrected magnitudes
        pool.execute(args.threads)

        logger.info("updating headers and closing data store")
        timestamp.finalize()
    # close the table and flush data
    logger.info("computation completed for {:,d} entries".format(len(table)))


if __name__ == "__main__":
    main()
