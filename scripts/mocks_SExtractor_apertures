#!/usr/bin/env python3
import argparse
import multiprocessing
import os
import sys
from multiprocessing import cpu_count

import numpy as np

from h5table.memmap import BinaryTable
from MICE2_mocks import pipeline


def root_function(args):
    """
    Wrapper for multiprocessing
    """
    return find_percentile(*args)


if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description='Compute the signal-to-noise ratio correction factor '
                    'for an extended object compared to a point source '
                    'assuming a n=4 Sersic profile for the bulge and a n=1 '
                    'Sersic profile for the disk component. The size is '
                    'defined in terms of a fraction of the total emitted flux '
                    '(i.e. 0.5 for the half-light radius.')
    parser.add_argument(
        'dataset', help='memory mapped table data set with MICE2 raw data')
    parser.add_argument(
        '-c', '--chunksize', type=int, default=10000 * cpu_count(),
        help='row chunk size to process at once (default: %(default)s)')
    parser.add_argument(
        '--flux-frac', type=float, default=0.5,
        help='fraction of total flux emitted from within computed radius '
             '(default: %(default)s)')
    parser.add_argument(
        '--psf', nargs='*', type=float, required=True,
        help='list of point-spread functions in arcsec, '
             'additionally computes observed galaxy sizes (PSF convolved)')
    parser.add_argument(
        '--filters', nargs='*', required=True,
        help='filter names associated with each --psf given (optional, used '
             'to name the output table columns)')
    parser.add_argument(
        '--scale', type=float, default=1.0,
        help='factor to scale the aperture size (default: %(default)s)')
    parser.add_argument(
        '--threads', type=int, default=cpu_count(),
        help='number of threads to use (default: %(default)s)')
    args = parser.parse_args()
    args.threads = min(cpu_count(), max(1, args.threads))

    logger = pipeline.pipe_logger(__file__)

    logger.info("loading data store '{:}'".format(args.dataset))
    with BinaryTable(args.dataset, mode="r+") as table:

        # find the shape columns
        path_dict = {
            "bulge ratio": "bulge_fraction",
            "bulge size": "bulge_length",
            "disk size": "disk_length",
            "axis ratio": "bulge_axis_ratio"}
        for name, path in path_dict.items():
            if path not in table:
                message = "{:} column {:} not found in data set"
                logger.error(message.format(name, path))
                raise KeyError(message.format(name, path))

        # generate list of PSF sizes and output columns names
        if len(args.psf) != len(args.filters):
            message = "length of --filter and --psf lists do not match"
            logger.error(message)
            raise ValueError(message)
        for psf in args.psf:
            if psf <= 0.0:
                message = "PSF size must be positive"
                logger.error(message)
                raise ValueError(message)
        psf_sizes = {
            key: val for key, val in zip(args.filters, args.psf)}
        # create new output columns
        col = table.add_column(
            "R_E", dtype=np.float32, attr={
                "description":
                "effective radius, L(<R_E) = {:2f} L_tot".format(
                    args.flux_frac)})
        col = table.add_column(
            "aper_a_intr", dtype=np.float32, attr={
                "description": "PSF corrected aperture major axis"})
        col = table.add_column(
            "aper_area_intr", dtype=np.float32, attr={
                "description": "PSF corrected aperture area"})

        # compute intrinsic galaxy sizes
        logger.info("computing intrinsic galaxy sizes")
        with multiprocessing.Pool(args.threads) as pool:
            for start, end in table.row_iter(args.chunksize):
                bulge_ratio = table[path_dict["bulge ratio"]][start:end]
                bulge_size = table[path_dict["bulge size"]][start:end]
                disk_size = table[path_dict["disk size"]][start:end]
                ba_ratio = table[path_dict["axis ratio"]][start:end]
                flux_fraction = np.full_like(bulge_ratio, args.flux_frac)
                # compute the radius of galaxies that emits a certain fraction of
                # the total luminosity
                arguments = list(zip(
                    flux_fraction, disk_size, bulge_size, bulge_ratio))
                chunksize = args.chunksize // args.threads + 1
                galaxy_size = pool.map(
                    root_function, arguments, chunksize=chunksize)
                # compute the intrinsic galaxy major and minor axes and area
                galaxy_major = np.asarray(galaxy_size) * args.scale
                galaxy_minor = galaxy_major * ba_ratio
                galaxy_area = np.pi * galaxy_major * galaxy_minor
                # write the data
                table["R_E"][start:end] = galaxy_size
                table["aper_a_intr"][start:end] = galaxy_major
                table["aper_area_intr"][start:end] = galaxy_area

        # compute the observational galaxy sizes utilizing the PSF per filter
        for filt in args.filters:
            logger.info(
                "computing observed galaxy sizes in filter '{:}'".format(filt))
            psf = psf_sizes[filt]
            # create new output columns
            aper_a = table.add_column(
                "aper_a_{:}".format(filt), dtype=np.float32, attr={
                    "description": "aperture major axis"})
            aper_ab = table.add_column(
                "aper_ba_ratio_{:}".format(filt), dtype=np.float32, attr={
                    "description": "aperture minor-to-major axis-ratio"})
            aper_area = table.add_column(
                "aper_area_{:}".format(filt), dtype=np.float32, attr={
                    "description": "aperture area"})
            sn_factor = table.add_column(
                "sn_factor_{:}".format(filt), dtype=np.float32, attr={
                    "description":
                    "signal-to-noise correction factor for extended source"})
            # compute the apertures
            for start, end in table.row_iter(args.chunksize):
                ba_ratio = table[path_dict["axis ratio"]][start:end]
                galaxy_major = table["aper_a_intr"][start:end]
                # "convolution" with the PSF
                observed_major = np.sqrt(galaxy_major**2 + psf**2)
                observed_minor = np.sqrt((galaxy_major * ba_ratio)**2 + psf**2)
                # compute the observed axis ratio
                observed_ba = observed_minor / observed_major
                # compute the aperture area
                observed_area = np.pi * observed_major * observed_minor
                psf_area = np.pi * psf**2
                # compute the S/N correction by comparing the aperture area to the PSF
                sn_weight = np.sqrt(psf_area / observed_area)
                # write the data
                aper_a[start:end] = observed_major
                aper_ab[start:end] = observed_ba
                aper_area[start:end] = observed_area
                sn_factor[start:end] = sn_weight

    logger.info("done")
