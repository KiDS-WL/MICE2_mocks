#!/usr/bin/env python3
import argparse
import multiprocessing
import os
import sys
from multiprocessing import cpu_count

import numpy as np
from astropy import units
from astropy.table import Column, Table
from scipy.optimize import root_scalar
from scipy.special import gamma, gammainc  # Gamma and incomplete Gamma

from table_tools import load_table


def FWHM_to_sigma(FWHM):
    conv = 2.0 * np.sqrt(2.0 * np.log(2.0))  # 2.355
    return FWHM / conv


def f_R_e(R, R_e_Disk, R_e_Bulge, f_B, percentile=0.5):
    """
    Function used to find the effective radius of a galaxy with combined
    bulge and disk component. Computes the fraction of the total flux emitted
    within a radius R minus a percentile. The percentile sets the zero-point
    of this function.

    By running a root-finding algorithm, the radius corresponding to a given
    percentile of emitted flux within can be computed. Setting the percentile
    to 0.5 yields the effective radius, the radius from within which 50% of the
    total flux are emitted.

    Parameters
    ----------
    R : float
        Radius (angular) at which to evaluate the function.
    R_e_Disk : float
        Effective angular size of the disk component.
    R_e_Bulge : float
        Effective angular size of the bulge component.
    f_B : float
        Bulge fraction, (flux bulge / total flux).
    percentile : float
        The percentile subtracted from the calculated flux fraction within R.

    Returns
    -------
    flux_fraction_offset : float
        Fraction of flux emitted within R minus percentile.
    """
    if R_e_Disk == 0.0 or f_B == 1.0:  # no disk component
        disk_term = 0.0
    else:  # evaluate the integrated Sersic n=1 profile
        x_D = 1.6721 * R / R_e_Disk
        disk_term = (1.0 - f_B) * gammainc(2, x_D)
    if R_e_Bulge == 0.0 or f_B == 0.0:  # no bulge component
        bulge_term = 0.0
    else:  # evaluate the integrated Sersic n=4 profile
        x_B = 7.6697 * (R / R_e_Bulge) ** 0.25
        bulge_term = f_B * gammainc(8, x_B)
    # disk_term and bulge_term are already normalized by the total flux
    flux_fraction_offset = disk_term + bulge_term - percentile
    return flux_fraction_offset


def f_R_e_derivative(R, R_e_Disk, R_e_Bulge, f_B, *args):
    """
    Derivative of f_R_e wrt. the radius used by the root-finding algorithm.

    Parameters
    ----------
    R : float
        Radius (angular) at which to evaluate the derivative.
    R_e_Disk : float
        Effective angular size of the disk component.
    R_e_Bulge : float
        Effective angular size of the bulge component.
    f_B : float
        Bulge fraction, (flux bulge / total flux).

    Returns
    -------
    flux_fraction_der : float
        Derivative of f_R_e.
    """
    if R_e_Disk == 0.0 or f_B == 1.0:  # no disk component
        disk_term = 0.0
    else:  # evaluate the derivative of the integrated Sersic n=1 profile
        b_1 = 1.6721
        x_D = b_1 * R / R_e_Disk
        disk_term = (1.0 - f_B) * np.exp(-x_D) * x_D / R_e_Disk * b_1
    if R_e_Bulge == 0.0 or f_B == 0.0:  # no bulge component
        bulge_term = 0.0
    else:  # evaluate the derivative of the integrated Sersic n=4 profile
        b_4 = 7.6697
        x_B = b_4 * (R / R_e_Bulge) ** 0.25
        bulge_term = (
            f_B * np.exp(-x_B) / 5040.0 * x_B**4 / R_e_Bulge * b_4**4 / 4.0)
    # combined derivative is sum of disk and bulge derivatives
    flux_fraction_der = disk_term + bulge_term
    return flux_fraction_der


def find_percentile(
        percentile, R_e_Disk, R_e_Bulge, f_B, method="newton"):
    """
    Compute the radius within which a certain percentile of flux is emitted
    using the scipy.optimize.root_scalar root-finding algorithm. By default
    the Newton's method is used.

    Parameters
    ----------
    percentile : float
        The percentile of emitted flux from within the radius of interest.
    R_e_Disk : float
        Effective angular size of the disk component.
    R_e_Bulge : float
        Effective angular size of the bulge component.
    f_B : float
        Bulge fraction, (flux bulge / total flux).
    method : sting
        Root-finding method to use (from scipy.optimize.root_scalar).

    Returns
    -------
    solution.root : float
        The radius within which the percentile of flux is emitted.
    """
    assert(0.0 <= f_B <= 1.0)
    assert(R_e_Disk >= 0.0 and R_e_Bulge >= 0.0)
    x0 = (1.0 - f_B) * R_e_Disk + f_B * R_e_Bulge
    solution = root_scalar(
        f_R_e, fprime=f_R_e_derivative, x0=x0, method=method, maxiter=100,
        args=(R_e_Disk, R_e_Bulge, f_B, percentile))
    return solution.root


def root_function(args):
    """
    Wrapper for multiprocessing
    """
    return find_percentile(*args)


if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description='Compute the signal-to-noise ratio correction factor '
                    'for an extended object compared to a point source '
                    'assuming a n=4 Sersic profile for the bulge and a n=1 '
                    'Sersic profile for the disk component. The size is '
                    'defined in terms of a fraction of the total emitted flux '
                    '(i.e. 0.5 for the half-light radius.')

    data_group = parser.add_argument_group('data')
    data_group.add_argument(
        '-i', '--input', required=True, help='file path of input data table')
    data_group.add_argument(
        '--iformat', default='fits',
        help='astropy.table format specifier of the input table '
             '(default: %(default)s)')
    data_group.add_argument(
        '-o', '--output', required=True, help='file path of output table')
    data_group.add_argument(
        '--oformat', default='fits',
        help='astropy.table format specifier of the output table '
             '(default: %(default)s)')

    params_group = parser.add_argument_group('parameters')
    params_group.add_argument(
        '--bulge-ratio', required=True,
        help='column name of bulge-to-total-flux ratio')
    params_group.add_argument(
        '--bulge-size', required=True,
        help='column name of projected bulge size (half light radius) in '
             'arcsec')
    params_group.add_argument(
        '--disk-size', required=True,
        help='column name of projected disk size (half light radius) in '
             'arcsec')
    params_group.add_argument(
        '--ba-ratio',
        help='column name of minor-to-major axis ratio')
    params_group.add_argument(
        '--flux-frac', type=float, default=0.5,
        help='fraction of total flux emitted from within computed radius '
             '(default: %(default)s)')
    params_group.add_argument(
        '--psf', nargs='*', type=float, required=True,
        help='list of FWHM point-spread functions in arcsec, '
             'additionally computes observed galaxy sizes (PSF convolved)')
    params_group.add_argument(
        '--filters', nargs='*',
        help='filter names associated with each --psf given (optional, used '
             'to name the output table columns)')
    params_group.add_argument(
        '--aper-min', type=float, default=0.0,
        help='minimum aperture size (default: %(default)s)')
    params_group.add_argument(
        '--aper-max', type=float, default=np.inf,
        help='maximum aperture size (default: no limit)')
    params_group.add_argument(
        '--threads', type=int, default=cpu_count(),
        help='number of threads to use (default: %(default)s)')

    args = parser.parse_args()

    setattr(args, "threads", min(cpu_count(), max(1, args.threads)))

    data = load_table(
        args.input, args.iformat,
        [args.bulge_ratio, args.bulge_size, args.disk_size, args.ba_ratio])

    # generate list of PSF sizes and output columns names
    if args.filters is not None:
        if len(args.psf) != len(args.filters):
            sys.exit("ERROR: length of --filter and --psf lists do not match")
        for psf in args.psf:
            if psf <= 0.0:
                sys.exit("ERROR: PSF size must be positive")
    else:
        setattr(
            args, "filters", ["filter%d" % d for d in range(len(args.psf))])
    psf_sizes = {
        key: val for key, val in zip(args.filters, args.psf)}

    # compute intrinsic galaxy sizes
    bulge_ratio = data[args.bulge_ratio]
    bulge_size = data[args.bulge_size]
    disk_size = data[args.disk_size]
    ba_ratio = data[args.ba_ratio]
    flux_fraction = np.full_like(bulge_ratio, args.flux_frac)
    # create an argument list for map / multiprocessing.pool.map
    arguments = list(zip(flux_fraction, disk_size, bulge_size, bulge_ratio))
    message = "compute intrinsic galaxy sizes"
    # compute the radius of galaxies that emits a certain fraction of the
    # total flux
    if args.threads > 1:
        print(message + " using %d threads" % args.threads)
        with multiprocessing.Pool(args.threads) as pool:
            galaxy_size = pool.map(root_function, arguments)
    else:
        print(message)
        galaxy_size = tuple(map(root_function, arguments))

    # create the output data table
    table = Table()
    # compute the intrinsic galaxy major and minor axes and area
    galaxy_major = np.asarray(galaxy_size)
    galaxy_minor = galaxy_major * ba_ratio
    galaxy_area = np.pi * galaxy_major * galaxy_minor
    table["a_intr"] = Column(
        galaxy_major, unit=units.arcsec,
        description="intrinsic galaxy major axis (sigma)")
    table["b_intr"] = Column(
        galaxy_minor, unit=units.arcsec,
        description="intrinsic galaxy minor axis (sigma)")

    # compute the convoluted galaxy properties and collect the data
    print("compute observed galaxy sizes")
    # compute the observational galaxy sizes utilizing the PSF per filter
    for filt in args.filters:
        psf = psf_sizes[filt]
        psf_sigma = FWHM_to_sigma(psf)
        print("processing filter '%s' (PSF=%.2f\")" % (filt, psf))
        # "convolution" with the PSF, corresponds to THELI A/B_WORLD
        observed_major = np.sqrt(galaxy_major**2 + psf_sigma**2)
        observed_minor = np.sqrt(galaxy_minor**2 + psf_sigma**2)
        table["a_obs_%s" % filt] = Column(
            observed_major, unit=units.arcsec,
            description="observed galaxy major axis (sigma, A_WORLD)")
        table["b_obs_%s" % filt] = Column(
            observed_minor, unit=units.arcsec,
            description="observed galaxy minor axis (sigma, B_WORLD)")
        # compute the GAaP-like aperture
        aperture_major = np.minimum(
            np.sqrt(observed_major**2 + args.aper_min**2),
            args.aper_max)  # clip at maximum aperture
        aperture_minor = np.minimum(
            np.sqrt(observed_minor**2 + args.aper_min**2),
            args.aper_max)  # clip at maximum aperture
        table["a_aper_%s" % filt] = Column(
            aperture_major, unit=units.arcsec,
            description="aperture major axis (sigma, Agaper)")
        table["b_aper_%s" % filt] = Column(
            aperture_minor, unit=units.arcsec,
            description="aperture minor axis (sigma, Bgaper)")
        # compute the aperture area
        aperture_area = np.pi * aperture_major * aperture_minor
        table["area_aper_%s" % filt] = Column(
            aperture_area, unit=units.arcsec**2,
            description="aperture area (sigma^2)")

    # write to specified output path
    print("write table to: %s" % args.output)
    table.write(args.output, format=args.oformat, overwrite=True)


def FWHM_to_sigma(FWHM):
    conv = 2.0 * np.sqrt(2.0 * np.log(2.0))  # 2.355
    return FWHM / conv


if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description='Create a data table with a photometery realisation based '
                    'on a table with simulated model magnitudes and '
                    'observational detection limits.')

    data_group = parser.add_argument_group('data')
    data_group.add_argument(
        '-i', '--input', required=True, help='file path of input data table')
    data_group.add_argument(
        '--i-format', default='fits',
        help='astropy.table format specifier of the input table '
             '(default: %(default)s)')
    data_group.add_argument(
        '-o', '--output', required=True, help='file path of output table')
    data_group.add_argument(
        '--o-format', default='fits',
        help='astropy.table format specifier of the output table '
             '(default: %(default)s)')

    params_group = parser.add_argument_group('parameters')
    params_group.add_argument(
        '--filters', nargs='*', required=True,
        help='list of table column names providing model magnitudes')
    params_group.add_argument(
        '--limits', nargs='*', type=float, required=True,
        help='magnitude limits for each entry in --filters')
    params_group.add_argument(
        '--aperture', type=float, required=True,
        help='aperture FWHM in arcsec in which the limits are computed')
    params_group.add_argument(
        '--aperture-areas', nargs='*',
        help='list of table column names of aperture areas for a correction '
             'of the signal-to-noise ratio relative to the aperture that '
             'was used to compute the magnitude limits')
    params_group.add_argument(
        '--significance', type=float, default=1.0,
        help='significance of detection against magnitude limits '
             '(default: %(default)s)')
    params_group.add_argument(
        '--sn-limit', type=float, default=0.2,
        help='lower numerical limit for the signal-to-noise ratio '
             '(default: %(default)s)')
    params_group.add_argument(
        '--sn-detect', type=float, default=1.0,
        help='limiting signal-to-noise ratio for object detection '
             '(default: %(default)s)')
    params_group.add_argument(
        '--seed', default='KV450',
        help='string to seed the random generator (default: %(default)s)')

    args = parser.parse_args()

    # check if all argument lengths match
    filters = args.filters
    if len(args.limits) != len(filters):
        sys.exit("ERROR: number of input --limits do not match --filters")
    if args.aperture_areas is None:
        aperture_areas = [None] * len(filters)
    else:
        aperture_areas = args.aperture_areas
        if len(aperture_areas) != len(filters):
            sys.exit(
                "ERROR: number of input --sn-factors do not match --filters")

    # load the data table and check that all required columsn exist
    columns = [f for f in filters]
    if args.aperture_areas is not None:
        columns.extend(aperture_areas)
    data = load_table(args.input, args.i_format, columns)
    print("use input filters: %s" % ", ".join(filters))

    # get all input magnitudes and their limits
    mag_model_data = {filt: data[filt] for filt in filters}
    mag_model_limits = {
        filt: lim for filt, lim in zip(filters, args.limits)}

    # create noise realisations
    SN_limit = args.sn_limit
    SN_detect = args.sn_detect
    non_detection_magnitude = 99.0  # inserted for non-detections
    # dictionaries that collect the magnitude realisations per filter
    mag_realisation_data = {}
    mag_realisation_error = {}
    # reseed the random state -> reproducible results
    hasher = md5(bytes(args.seed, "utf-8"))
    hashval = bytes(hasher.hexdigest(), "utf-8")
    np.random.seed(np.frombuffer(hashval, dtype=np.uint32))
    for filt, aper_key in zip(filters, aperture_areas):
        if aper_key is None:
            SN_factor = 1.0
        else:
            SN_factor = np.sqrt(
                np.pi * FWHM_to_sigma(args.aperture)**2 /  # mag-lim aperture
                data[aper_key])  # galaxy aperture
        model_mags = mag_model_data[filt]
        print("processing filter '%s'" % filt)
        # compute model fluxes and the S/N
        model_flux = 10 ** (-0.4 * model_mags)
        flux_err = 10 ** (-0.4 * mag_model_limits[filt])  # universal
        model_SN = model_flux / flux_err * args.significance
        model_SN *= SN_factor  # aperture correction
        # compute the magnitde realisation and S/N
        real_flux = np.random.normal(  # approximation for Poisson error
            model_flux, flux_err, size=len(model_SN))
        real_flux = np.maximum(real_flux, 1e-3 * flux_err)
        real_SN = real_flux / flux_err * args.significance
        real_SN *= SN_factor  # aperture correction
        real_SN = np.maximum(real_SN, SN_limit)  # clip SN
        # compute the magnitude realisation
        real_mags = -2.5 * np.log10(real_flux)
        mags_err = 2.5 / np.log(10.0) / real_SN  # universal
        # set magnitudes of undetected objects and mag < 5.0 to 99.0
        not_detected = (real_SN < SN_detect) | (real_mags < 5.0)
        real_mags[not_detected] = non_detection_magnitude
        mags_err[not_detected] = (
            mag_model_limits[filt] - 2.5 * np.log10(args.significance))
        # collect the results
        mag_realisation_data[filt] = real_mags.astype(np.float32)
        mag_realisation_error[filt] = mags_err.astype(np.float32)

    # collect output data
    table = Table()
    for filt in filters:
        # find the correct magnitude column suffix depending on whether
        # magnification was applied or not
        if "_evo" in filt:
            key = filt.replace("_evo", "_obs")
            keyerr = filt.replace("_evo", "_obserr")
        else:
            if filt.endswith("_mag"):
                key = filt[:-4] + "_obs_mag"
                keyerr = filt[:-4] + "_obserr_mag"
            else:
                key = filt + "_obs"
                keyerr = filt + "_obserr"
        table[key] = Column(
            mag_realisation_data[filt], unit=units.mag,
            description="realisation of model magnitude")
        table[keyerr] = Column(
            mag_realisation_error[filt], unit=units.mag,
            description="error of realisation of model magnitude")

    # write to specified output path
    print("write table to: %s" % args.output)
    table.write(args.output, format=args.o_format, overwrite=True)
