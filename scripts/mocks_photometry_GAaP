#!/usr/bin/env python3
import argparse
import multiprocessing
import os
import sys
from multiprocessing import cpu_count

import numpy as np
from astropy import units
from astropy.table import Column, Table
from scipy.optimize import root_scalar
from scipy.special import gamma, gammainc  # Gamma and incomplete Gamma

from table_tools import load_table


if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description='Compute the signal-to-noise ratio correction factor '
                    'for an extended object compared to a point source '
                    'assuming a n=4 Sersic profile for the bulge and a n=1 '
                    'Sersic profile for the disk component. The size is '
                    'defined in terms of a fraction of the total emitted flux '
                    '(i.e. 0.5 for the half-light radius.')

    data_group = parser.add_argument_group('data')
    data_group.add_argument(
        '-i', '--input', required=True, help='file path of input data table')
    data_group.add_argument(
        '--iformat', default='fits',
        help='astropy.table format specifier of the input table '
             '(default: %(default)s)')
    data_group.add_argument(
        '-o', '--output', required=True, help='file path of output table')
    data_group.add_argument(
        '--oformat', default='fits',
        help='astropy.table format specifier of the output table '
             '(default: %(default)s)')

    params_group = parser.add_argument_group('parameters')
    params_group.add_argument(
        '--bulge-ratio', required=True,
        help='column name of bulge-to-total-flux ratio')
    params_group.add_argument(
        '--bulge-size', required=True,
        help='column name of projected bulge size (half light radius) in '
             'arcsec')
    params_group.add_argument(
        '--disk-size', required=True,
        help='column name of projected disk size (half light radius) in '
             'arcsec')
    params_group.add_argument(
        '--ba-ratio',
        help='column name of minor-to-major axis ratio')
    params_group.add_argument(
        '--flux-frac', type=float, default=0.5,
        help='fraction of total flux emitted from within computed radius '
             '(default: %(default)s)')
    params_group.add_argument(
        '--psf', nargs='*', type=float, required=True,
        help='list of FWHM point-spread functions in arcsec, '
             'additionally computes observed galaxy sizes (PSF convolved)')
    params_group.add_argument(
        '--filters', nargs='*',
        help='filter names associated with each --psf given (optional, used '
             'to name the output table columns)')
    params_group.add_argument(
        '--aper-min', type=float, default=0.0,
        help='minimum aperture size (default: %(default)s)')
    params_group.add_argument(
        '--aper-max', type=float, default=np.inf,
        help='maximum aperture size (default: no limit)')
    params_group.add_argument(
        '--threads', type=int, default=cpu_count(),
        help='number of threads to use (default: %(default)s)')

    args = parser.parse_args()

    setattr(args, "threads", min(cpu_count(), max(1, args.threads)))

    data = load_table(
        args.input, args.iformat,
        [args.bulge_ratio, args.bulge_size, args.disk_size, args.ba_ratio])

    # generate list of PSF sizes and output columns names
    if args.filters is not None:
        if len(args.psf) != len(args.filters):
            sys.exit("ERROR: length of --filter and --psf lists do not match")
        for psf in args.psf:
            if psf <= 0.0:
                sys.exit("ERROR: PSF size must be positive")
    else:
        setattr(
            args, "filters", ["filter%d" % d for d in range(len(args.psf))])
    psf_sizes = {
        key: val for key, val in zip(args.filters, args.psf)}

    # compute intrinsic galaxy sizes
    bulge_ratio = data[args.bulge_ratio]
    bulge_size = data[args.bulge_size]
    disk_size = data[args.disk_size]
    ba_ratio = data[args.ba_ratio]
    flux_fraction = np.full_like(bulge_ratio, args.flux_frac)
    # create an argument list for map / multiprocessing.pool.map
    arguments = list(zip(flux_fraction, disk_size, bulge_size, bulge_ratio))
    message = "compute intrinsic galaxy sizes"
    # compute the radius of galaxies that emits a certain fraction of the
    # total flux
    if args.threads > 1:
        print(message + " using %d threads" % args.threads)
        with multiprocessing.Pool(args.threads) as pool:
            galaxy_size = pool.map(root_function, arguments)
    else:
        print(message)
        galaxy_size = tuple(map(root_function, arguments))

    # create the output data table
    table = Table()
    # compute the intrinsic galaxy major and minor axes and area
    galaxy_major = np.asarray(galaxy_size)
    galaxy_minor = galaxy_major * ba_ratio
    galaxy_area = np.pi * galaxy_major * galaxy_minor
    table["a_intr"] = Column(
        galaxy_major, unit=units.arcsec,
        description="intrinsic galaxy major axis (sigma)")
    table["b_intr"] = Column(
        galaxy_minor, unit=units.arcsec,
        description="intrinsic galaxy minor axis (sigma)")

    # compute the convoluted galaxy properties and collect the data
    print("compute observed galaxy sizes")
    # compute the observational galaxy sizes utilizing the PSF per filter
    for filt in args.filters:
        psf = psf_sizes[filt]
        psf_sigma = FWHM_to_sigma(psf)
        print("processing filter '%s' (PSF=%.2f\")" % (filt, psf))
        # "convolution" with the PSF, corresponds to THELI A/B_WORLD
        observed_major = np.sqrt(galaxy_major**2 + psf_sigma**2)
        observed_minor = np.sqrt(galaxy_minor**2 + psf_sigma**2)
        table["a_obs_%s" % filt] = Column(
            observed_major, unit=units.arcsec,
            description="observed galaxy major axis (sigma, A_WORLD)")
        table["b_obs_%s" % filt] = Column(
            observed_minor, unit=units.arcsec,
            description="observed galaxy minor axis (sigma, B_WORLD)")
        # compute the GAaP-like aperture
        aperture_major = np.minimum(
            np.sqrt(observed_major**2 + args.aper_min**2),
            args.aper_max)  # clip at maximum aperture
        aperture_minor = np.minimum(
            np.sqrt(observed_minor**2 + args.aper_min**2),
            args.aper_max)  # clip at maximum aperture
        table["a_aper_%s" % filt] = Column(
            aperture_major, unit=units.arcsec,
            description="aperture major axis (sigma, Agaper)")
        table["b_aper_%s" % filt] = Column(
            aperture_minor, unit=units.arcsec,
            description="aperture minor axis (sigma, Bgaper)")
        # compute the aperture area
        aperture_area = np.pi * aperture_major * aperture_minor
        table["area_aper_%s" % filt] = Column(
            aperture_area, unit=units.arcsec**2,
            description="aperture area (sigma^2)")

    # write to specified output path
    print("write table to: %s" % args.output)
    table.write(args.output, format=args.oformat, overwrite=True)


if __name__ == "__main__":

    parser = argparse.ArgumentParser(
        description='Create a data table with a photometery realisation based '
                    'on a table with simulated model magnitudes and '
                    'observational detection limits.')

    data_group = parser.add_argument_group('data')
    data_group.add_argument(
        '-i', '--input', required=True, help='file path of input data table')
    data_group.add_argument(
        '--i-format', default='fits',
        help='astropy.table format specifier of the input table '
             '(default: %(default)s)')
    data_group.add_argument(
        '-o', '--output', required=True, help='file path of output table')
    data_group.add_argument(
        '--o-format', default='fits',
        help='astropy.table format specifier of the output table '
             '(default: %(default)s)')

    params_group = parser.add_argument_group('parameters')
    params_group.add_argument(
        '--filters', nargs='*', required=True,
        help='list of table column names providing model magnitudes')
    params_group.add_argument(
        '--limits', nargs='*', type=float, required=True,
        help='magnitude limits for each entry in --filters')
    params_group.add_argument(
        '--aperture', type=float, required=True,
        help='aperture FWHM in arcsec in which the limits are computed')
    params_group.add_argument(
        '--aperture-areas', nargs='*',
        help='list of table column names of aperture areas for a correction '
             'of the signal-to-noise ratio relative to the aperture that '
             'was used to compute the magnitude limits')
    params_group.add_argument(
        '--significance', type=float, default=1.0,
        help='significance of detection against magnitude limits '
             '(default: %(default)s)')
    params_group.add_argument(
        '--sn-limit', type=float, default=0.2,
        help='lower numerical limit for the signal-to-noise ratio '
             '(default: %(default)s)')
    params_group.add_argument(
        '--sn-detect', type=float, default=1.0,
        help='limiting signal-to-noise ratio for object detection '
             '(default: %(default)s)')
    params_group.add_argument(
        '--seed', default='KV450',
        help='string to seed the random generator (default: %(default)s)')

    args = parser.parse_args()

    # check if all argument lengths match
    filters = args.filters
    if len(args.limits) != len(filters):
        sys.exit("ERROR: number of input --limits do not match --filters")
    if args.aperture_areas is None:
        aperture_areas = [None] * len(filters)
    else:
        aperture_areas = args.aperture_areas
        if len(aperture_areas) != len(filters):
            sys.exit(
                "ERROR: number of input --sn-factors do not match --filters")

    # load the data table and check that all required columsn exist
    columns = [f for f in filters]
    if args.aperture_areas is not None:
        columns.extend(aperture_areas)
    data = load_table(args.input, args.i_format, columns)
    print("use input filters: %s" % ", ".join(filters))

    # get all input magnitudes and their limits
    mag_model_data = {filt: data[filt] for filt in filters}
    mag_model_limits = {
        filt: lim for filt, lim in zip(filters, args.limits)}

    # create noise realisations
    SN_limit = args.sn_limit
    SN_detect = args.sn_detect
    non_detection_magnitude = 99.0  # inserted for non-detections
    # dictionaries that collect the magnitude realisations per filter
    mag_realisation_data = {}
    mag_realisation_error = {}
    # reseed the random state -> reproducible results
    hasher = md5(bytes(args.seed, "utf-8"))
    hashval = bytes(hasher.hexdigest(), "utf-8")
    np.random.seed(np.frombuffer(hashval, dtype=np.uint32))
    for filt, aper_key in zip(filters, aperture_areas):
        if aper_key is None:
            SN_factor = 1.0
        else:
            SN_factor = np.sqrt(
                np.pi * FWHM_to_sigma(args.aperture)**2 /  # mag-lim aperture
                data[aper_key])  # galaxy aperture
        model_mags = mag_model_data[filt]
        print("processing filter '%s'" % filt)
        # compute model fluxes and the S/N
        model_flux = 10 ** (-0.4 * model_mags)
        flux_err = 10 ** (-0.4 * mag_model_limits[filt])  # universal
        model_SN = model_flux / flux_err * args.significance
        model_SN *= SN_factor  # aperture correction
        # compute the magnitde realisation and S/N
        real_flux = np.random.normal(  # approximation for Poisson error
            model_flux, flux_err, size=len(model_SN))
        real_flux = np.maximum(real_flux, 1e-3 * flux_err)
        real_SN = real_flux / flux_err * args.significance
        real_SN *= SN_factor  # aperture correction
        real_SN = np.maximum(real_SN, SN_limit)  # clip SN
        # compute the magnitude realisation
        real_mags = -2.5 * np.log10(real_flux)
        mags_err = 2.5 / np.log(10.0) / real_SN  # universal
        # set magnitudes of undetected objects and mag < 5.0 to 99.0
        not_detected = (real_SN < SN_detect) | (real_mags < 5.0)
        real_mags[not_detected] = non_detection_magnitude
        mags_err[not_detected] = (
            mag_model_limits[filt] - 2.5 * np.log10(args.significance))
        # collect the results
        mag_realisation_data[filt] = real_mags.astype(np.float32)
        mag_realisation_error[filt] = mags_err.astype(np.float32)

    # collect output data
    table = Table()
    for filt in filters:
        # find the correct magnitude column suffix depending on whether
        # magnification was applied or not
        if "_evo" in filt:
            key = filt.replace("_evo", "_obs")
            keyerr = filt.replace("_evo", "_obserr")
        else:
            if filt.endswith("_mag"):
                key = filt[:-4] + "_obs_mag"
                keyerr = filt[:-4] + "_obserr_mag"
            else:
                key = filt + "_obs"
                keyerr = filt + "_obserr"
        table[key] = Column(
            mag_realisation_data[filt], unit=units.mag,
            description="realisation of model magnitude")
        table[keyerr] = Column(
            mag_realisation_error[filt], unit=units.mag,
            description="error of realisation of model magnitude")

    # write to specified output path
    print("write table to: %s" % args.output)
    table.write(args.output, format=args.o_format, overwrite=True)
