#!/usr/bin/env python3
import argparse
import os
import sys

import mock_processing as mocks
from mock_processing.core.config import Photometry_Parser
from mock_processing.photometry import apertures_wrapped


parser = argparse.ArgumentParser(
    description="Create a photometric apertures based on the intrisic galaxy "
                "and PSF sizes.",
    add_help=False)
parser.register("action", "dump", Photometry_Parser.get_dump())

parser.add_argument(
    "datastore", help="directory in which the data store is located")

parser.add_argument(
    "--method", choices=("SExtractor", "GAaP"), default="SExtractor",
    help="photometry algorthim to apply (default: %(default)s)")
parser.add_argument(
    "-c", "--config", required=True,
    help="parameter file in TOML format that defines the properties of the "
         "photometry realisation and the method parameters (use --dump to "
         "obtain a default parameter file)")
parser.add_argument(
    "--threads", type=int, default=-1,
    help="maximum number of threads to use (default: all)")

help_group = parser.add_argument_group("help and documentation")
help_group.add_argument(
    "-h", "--help", action="help",
    help="show this help message and exit")
help_group.add_argument(
    "--dump", nargs=0, action="dump",
    help="dump a default photometry configuratin file to stdout and exit")


def main():

    args = parser.parse_args()
    logger = mocks.PipeLogger(__file__, args.datastore)

    # check the configuration file
    config = Photometry_Parser(args.config, logger)

    # apply the magnification correction to the model magnitudes
    with mocks.DataStore.open(args.datastore, False, logger=logger) as ds:
        ds.pool.max_threads = args.threads

        # initialize the aperture computation
        ds.pool.set_worker(apertures_wrapped)
        ds.pool.add_argument_constant(args.method)
        ds.pool.add_argument_constant(config)

        # find effective radius and b/a ratio columns
        input_columns = (
            ("effective radius", "shape/R_effective"),
            ("b/a ratio", "shape/axis_ratio"))
        for col_desc, path in input_columns:
            ds.require_column(path, col_desc)
            ds.pool.add_argument_column(path)

        output_columns = (  # for each filter three output columns are required
            ("apertures/{:}/major_axis/{:}",
                "{:} aperture major axis (PSF size: {:.2f}\")"),
            ("apertures/{:}/minor_axis/{:}",
                "{:} aperture minor axis (PSF size: {:.2f}\")"),
            ("apertures/{:}/snr_correction/{:}",
                "{:} aperture S/N correction (PSF size: {:.2f}\")"))
        # make the output columns for each filter
        for key in config.filter_names:
            for out_path, desc in output_columns:
                ds.add_column(
                    out_path.format(args.method, key),
                    dtype="f4", overwrite=True, attr={
                        "description":
                        desc.format(args.method, config.PSF[key])})
                # collect all new columns as output targets
                ds.pool.add_result_column(out_path.format(args.method, key))

        # compute and store the apertures
        ds.pool.execute()
        logger.info("computation completed for {:,d} entries".format(len(ds)))


if __name__ == "__main__":
    main()
