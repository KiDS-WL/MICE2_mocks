#!/usr/bin/env python3
import argparse
import os

from memmap_table import MemmapTable
from mock_processing import expand_path
from mock_processing.utils import build_history, bytesize_with_prefix


parser = argparse.ArgumentParser(
    description="Select a (sub-)sample of the pipeline output and save it "
                "in a different data format")
parser.add_argument(
    "datastore", type=expand_path,
    help="directory in which the data store is created")
parser.add_argument(
    "-c", "--columns", action="store_true", help="show the column data types")
parser.add_argument(
    "-a", "--attr", action="store_true", help="show the column attributes")
parser.add_argument(
    "-p", "--history", action="store_true", help="show the pipeline history")
parser.add_argument(
    "-l", "--logs", action="store_true",
    help="show the attached pipeline logs")


def main():

    args = parser.parse_args()
    with MemmapTable(args.datastore) as table:

        # display the table meta data
        print("==> META DATA")
        size = bytesize_with_prefix(table.nbytes)
        n_cols, n_rows = table.shape
        print("root:     {:}".format(table.root))
        print("size:     {:}".format(size))
        print("shape:    {:,d} rows x {:d} columns".format(n_rows, n_cols))

        if args.columns:
            # list all the column names and data types
            header = "==> COLUMN NAME"
            width_cols = max(len(header), max(
                len(colname) for colname in table.colnames))
            print("\n{:}    {:}".format(header.ljust(width_cols), "TYPE"))
            for name in table.colnames:
                colname_padded = name.ljust(width_cols)
                line = "{:}    {:}".format(
                    colname_padded, str(table[name].dtype))
                print(line)

        if args.attr:
            # for each column print a summary of the attached attributes
            print("\n==> ATTRIBUTES")
            for name in table.colnames:
                print()
                # print the column name indented and then a tree-like listing
                # of the attributes (drawing connecting lines for better
                # visibitilty)
                print("{:}".format(name))
                attrs = table[name].attr
                # all attributes from the pipeline should be dictionaries
                if type(attrs) is dict:
                    i_last = len(attrs)
                    width_key = max(len(key) + 2 for key in attrs)
                    for i, key in enumerate(sorted(attrs), 1):
                        print_key = key + " :"
                        line = "{:}{:} {:}".format(
                            " └╴ " if i == i_last else " ├╴ ",
                            print_key.ljust(width_key), str(attrs[key]))
                        print(line)
                # fallback
                else:
                    print("     └╴ {:}".format(str(attrs)))

        if args.history:
            # list all pipeline script calls ordered by time
            print("\n==> HISTORY")
            date_width = 24
            for date, call in build_history(table).items():
                print("{:} : {:}".format(date.ljust(date_width), call))

        if args.logs:
            # show the log file
            print("\n==> LOGS")
            logpath = table.root + ".log"
            if not os.path.exists(logpath):
                raise OSError("log file not found: {:}".format(logpath))
            with open(logpath) as f:
                for line in f.readlines():
                    print(line.strip())


if __name__ == "__main__":
    main()
